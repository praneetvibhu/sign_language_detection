{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathologic Cancer Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "###################################################\n",
    "# Abhyuday Puri (ap3758)                          #\n",
    "# Columbia University                             #\n",
    "# ECBM E6040                                      #\n",
    "###################################################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prane\\Anaconda3\\envs\\speech\\lib\\site-packages\\sklearn\\utils\\fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the labelled data and split it into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 176020\n",
      "Number of validation examples: 44005\n"
     ]
    }
   ],
   "source": [
    "# Reading the image ids and labels\n",
    "label = pd.read_csv('../data/train_labels.csv')\n",
    "\n",
    "# Splitting the data into training and validation with a 80/20 split\n",
    "train, val = train_test_split(label, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Re-indexing the validation dataframe\n",
    "val = val.reset_index(drop = True)\n",
    "\n",
    "print('Number of training examples:', train.shape[0])\n",
    "print('Number of validation examples:', val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the CNN architecture\n",
    "This network consists of 3 convolutional layers, 2 fully connected layers, and Batch Normalization after every intermediate layer. I use the ReLU activation function at the output of every intermediate layer, and a Sigmoid activation at the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 256, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3 = nn.Conv2d(256, 128, 3)\n",
    "        self.conv3_bn = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128 * 10 * 10, 64)\n",
    "        self.fc1_bn = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.conv3_bn(self.conv3(x))))\n",
    "        x = x.view(-1, 128 * 10 * 10)\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = self.out_act(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the network and moving it onto the GPU (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used = cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=12800, out_features=64, bias=True)\n",
       "  (fc1_bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (out_act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the network\n",
    "net = Net()\n",
    "\n",
    "# Checking if there is a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device being used =', device)\n",
    "\n",
    "# Transferring the network onto the GPU\n",
    "net.to(device)\n",
    "\n",
    "# Ensuring that the model is in the training mode\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the loss function criteria\n",
    "criterion = nn.BCELoss()    # This is the Binary Cross Entropy Loss Function\n",
    "\n",
    "# Choosing the optimizer and its hyper-parameters\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)    # Adaptive Momentum Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the hyper-parameters for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of train and val examples\n",
    "num_train = train.shape[0]\n",
    "num_val = val.shape[0]\n",
    "\n",
    "# Hyper-Parameters\n",
    "num_epochs = 5\n",
    "batch_size = 200\n",
    "num_iters = num_train // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, mini_batch: 200 loss: 0.48549992755055427\n",
      "epoch: 0, mini_batch: 400 loss: 0.4191173976659775\n",
      "epoch: 0, mini_batch: 600 loss: 0.3790909260511398\n",
      "epoch: 0, mini_batch: 800 loss: 0.3589572809636593\n",
      "epoch: 1, mini_batch: 200 loss: 0.33026263549923895\n",
      "epoch: 1, mini_batch: 400 loss: 0.3192927210777998\n",
      "epoch: 1, mini_batch: 600 loss: 0.3040379475057125\n",
      "epoch: 1, mini_batch: 800 loss: 0.28980055086314677\n",
      "epoch: 2, mini_batch: 200 loss: 0.2721355623751879\n",
      "epoch: 2, mini_batch: 400 loss: 0.26051641188561914\n",
      "epoch: 2, mini_batch: 600 loss: 0.25267469048500063\n",
      "epoch: 2, mini_batch: 800 loss: 0.24934985160827636\n",
      "epoch: 3, mini_batch: 200 loss: 0.22685006506741046\n",
      "epoch: 3, mini_batch: 400 loss: 0.2178252487629652\n",
      "epoch: 3, mini_batch: 600 loss: 0.2173678969591856\n",
      "epoch: 3, mini_batch: 800 loss: 0.21474242232739926\n",
      "epoch: 4, mini_batch: 200 loss: 0.18960166309028864\n",
      "epoch: 4, mini_batch: 400 loss: 0.18701070252805949\n",
      "epoch: 4, mini_batch: 600 loss: 0.18704144041985274\n",
      "epoch: 4, mini_batch: 800 loss: 0.18400734290480614\n",
      "Finished Training\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm6040/dlenv/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff16f9836a0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stores the loss through out the entire training\n",
    "training_loss = []\n",
    "\n",
    "# Variables to store the mini-batch data\n",
    "batch_image = torch.zeros(batch_size, 3, 96, 96)\n",
    "batch_y = torch.zeros(batch_size, 1)\n",
    "\n",
    "# loop over the dataset multiple times\n",
    "for epoch in range(num_epochs):  \n",
    "    \n",
    "    # Stores the loss for an entire mini-batch\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Shuffling the training dataset for each epoch\n",
    "    train = train.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Loop over the entire training dataset\n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Create the mini batch\n",
    "        for j in range(batch_size):\n",
    "            # get the inputs\n",
    "            name = train['id'][i * batch_size + j] \n",
    "            y = train['label'][i * batch_size + j]\n",
    "            # Read the image\n",
    "            image = plt.imread('../data/train/' + name + '.tif')\n",
    "            # Convert the image into a tensor\n",
    "            image = torch.tensor(image).float()\n",
    "            # Arrange the image in the desired order\n",
    "            batch_image[j, :] = image.permute(2, 0, 1)\n",
    "            # Converting the label to a tensor\n",
    "            batch_y[j] = torch.tensor(y).float()\n",
    "         \n",
    "        # Moving the mini-batch onto the GPU\n",
    "        batch_image, batch_y = batch_image.to(device), batch_y.to(device)\n",
    "        \n",
    "        # Forward Propogation\n",
    "        outputs = net(batch_image)\n",
    "        \n",
    "        # Computng the loss\n",
    "        loss = criterion(outputs, batch_y)\n",
    "           \n",
    "        # Back Propogation    \n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating the network parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print Loss\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 0 and i != 0:    # print every 200 mini-batches\n",
    "            print('epoch: {}, mini_batch: {} loss: {}'.format(epoch, i, running_loss / 200))\n",
    "            training_loss.append(running_loss / 200)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')\n",
    "\n",
    "# Saving the model\n",
    "torch.save(net, 'Network_3_1.pth')\n",
    "print('Model Saved')\n",
    "\n",
    "# Plotting the loss curve\n",
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the training loss decreases with the number of iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 90.18293375752755\n"
     ]
    }
   ],
   "source": [
    "# Load the saved network\n",
    "net = torch.load('Network_3_1.pth')\n",
    "\n",
    "# Transferring the network onto the GPU\n",
    "net.to(device)\n",
    "\n",
    "# Ensuring the model runs in the test mode\n",
    "# This freezes the values of the model parameters and does not update them\n",
    "net.eval()\n",
    "\n",
    "# Creating tensors to store the image and label\n",
    "val_image = torch.zeros(1, 3, 96, 96)\n",
    "val_y = torch.tensor(0).float()\n",
    "\n",
    "# Stores the number of correct prediction our model makes\n",
    "correct = 0\n",
    "\n",
    "for j in range(num_val):\n",
    "    # get the input data\n",
    "    name = val['id'][j] \n",
    "    y = val['label'][j]\n",
    "    \n",
    "    # Read the image\n",
    "    image = plt.imread('../data/train/' + name + '.tif')\n",
    "    # Converting the image into a tensor\n",
    "    image = torch.tensor(image).float()\n",
    "    # Re-arranging the axis of the image into the desired order\n",
    "    val_image[0, :] = image.permute(2, 0, 1)\n",
    "    # Converting the label into a tensor\n",
    "    val_y = torch.tensor(y).float()\n",
    "    \n",
    "    # Transferring the data onto the GPU\n",
    "    val_image, val_y = val_image.to(device), val_y.to(device)\n",
    "    \n",
    "    # Running inference on the mini-batch\n",
    "    outputs = net(val_image)\n",
    "\n",
    "    # Checking the prediction with the ground truth label\n",
    "    if outputs >= 0.5 and val_y == 1:\n",
    "        correct += 1\n",
    "    elif outputs < 0.5 and val_y ==0:\n",
    "        correct += 1\n",
    "        \n",
    "print('Validation Accuracy:', 100 * correct / num_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing examples: 57458\n"
     ]
    }
   ],
   "source": [
    "# Reading the test image names\n",
    "test = pd.read_csv('../data/sample_submission.csv')\n",
    "print('Number of testing examples:', test.shape[0])\n",
    "\n",
    "# Storing the number of training examples\n",
    "num_test = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = torch.zeros(1, 3, 96, 96)\n",
    "\n",
    "# Creating the CSV file to store the result\n",
    "with open('attempt_4.csv', 'wt') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    # Writing the header row for the submission file\n",
    "    filewriter.writerow(['id', 'label'])\n",
    "    for j in range(num_test):\n",
    "        \n",
    "        # get the input image name\n",
    "        name = test['id'][j] \n",
    "        \n",
    "        # Read the image\n",
    "        image = plt.imread('../data/test/' + name + '.tif')\n",
    "        image = torch.tensor(image).float()\n",
    "        test_image[0, :] = image.permute(2, 0, 1)\n",
    "    \n",
    "        # Transferring data onto the GPU\n",
    "        test_image = test_image.to(device)\n",
    "        \n",
    "        # Predicting the label for the input\n",
    "        outputs = net(test_image)\n",
    "        \n",
    "        # Writing the label to the submission file\n",
    "        if outputs >= 0.5:\n",
    "            filewriter.writerow([name, 1])\n",
    "        else:\n",
    "            filewriter.writerow([name, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the result of this network on the Kaggle Test dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attempt_4.png\" style=\"height:200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried 3 networks for this task, and so far, this has given the best result. Below is a table that summarizes the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Network     | Accuracy  |\n",
    "|-------------|-----------|\n",
    "|  Network 1  |   80.2    |\n",
    "|  Network 1 + BN  |   82.7    |\n",
    "|  Network 3  |   85.7    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section discusses the arhcitecture of the 3 networks (All filters are of size $ 3 \\times 3$):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Network 1:</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    Layer       |    Number of Filters/Neurons |\n",
    "|----------------|------------------------------|\n",
    "|    conv1       |                64            |\n",
    "|    maxpool     |                (2,2)         |\n",
    "|    conv2       |                128           |\n",
    "|    maxpool     |                (2,2)         |\n",
    "|    conv3       |                128           |\n",
    "|    maxpool     |                (2,2)         |\n",
    "|    fc1         |                (12800, 64)   |\n",
    "|    fc2         |                (64, 2)       |\n",
    "|    sigmoid     |                (1, 2)        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Network 2:</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    Layer       |    Number of Filters/Neurons |\n",
    "|----------------|------------------------------|\n",
    "|    conv1 + BN  |                64            |\n",
    "|    maxpool     |                (2,2)         |\n",
    "|    conv2 + BN  |                128           |\n",
    "|    maxpool     |                (2,2)         |\n",
    "|    conv3 + BN  |                128           |\n",
    "|    maxpool     |                (2,2)         |\n",
    "|    fc1 + BN    |                (12800, 64)   |\n",
    "|    fc2         |                (64, 2)       |\n",
    "|    sigmoid     |                (1, 2)        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Network 3:</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    Layer       |    Number of Filters/Neurons |\n",
    "|----------------|------------------------------|\n",
    "|    conv1 + BN  |                64            |\n",
    "|    maxpool     |                (2,2)         |\n",
    "|    conv2 + BN  |                256           |\n",
    "|    maxpool     |                (2,2)         |\n",
    "|    conv3 + BN  |                128           |\n",
    "|    maxpool     |                (2,2)         |\n",
    "|    fc1 + BN    |                (12800, 64)   |\n",
    "|    fc2         |                (64, 2)       |\n",
    "|    sigmoid     |                (1, 2)        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
